{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#documentation","title":"Documentation","text":"<p>Documentation for group50</p>"},{"location":"my_api/","title":"My API","text":""},{"location":"my_api/#group50.model.EmotionModel","title":"group50.model.EmotionModel","text":"<p>               Bases: <code>Module</code></p> <p>A PyTorch module for emotion classification using a pretrained backbone. This model leverages the TIMM library to instantiate a ResNet architecture adapted for a specific number of emotion classes.</p> <p>Attributes:</p> Name Type Description <code>backbone</code> <p>The neural network architecture used for feature extraction.</p> Source code in <code>group50/model.py</code> <pre><code>class EmotionModel(nn.Module):\n    \"\"\"\n    A PyTorch module for emotion classification using a pretrained backbone.\n    This model leverages the TIMM library to instantiate a ResNet architecture\n    adapted for a specific number of emotion classes.\n\n    Attributes:\n        backbone: The neural network architecture used for feature extraction.\n    \"\"\"\n\n    def __init__(self, model_name=\"resnet18\", num_classes=7, pretrained=True):\n        \"\"\"\n        Initializes the EmotionModel.\n        Args:\n            model_name: The name of the model architecture from the timm library.\n            num_classes: The number of output classes (emotions).\n            pretrained: Whether to load ImageNet pretrained weights.\n        \"\"\"\n        super().__init__()\n        # Load the pretrained backbone\n        # in_chans=1 are grayscale but 3 is safer for standard ResNet\n        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes, in_chans=3)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        if x.ndim != 4:\n            raise ValueError(\"Expected input to a 4D tensor\")\n        if x.shape[1] != 3 or x.shape[2] != 48 or x.shape[3] != 48:\n            raise ValueError(\"Expected each sample to have shape [3, 48, 48]\")\n\n        return self.backbone(x)\n</code></pre>"},{"location":"my_api/#group50.model.EmotionModel.__init__","title":"__init__","text":"<pre><code>__init__(model_name='resnet18', num_classes=7, pretrained=True)\n</code></pre> <p>Initializes the EmotionModel. Args:     model_name: The name of the model architecture from the timm library.     num_classes: The number of output classes (emotions).     pretrained: Whether to load ImageNet pretrained weights.</p> Source code in <code>group50/model.py</code> <pre><code>def __init__(self, model_name=\"resnet18\", num_classes=7, pretrained=True):\n    \"\"\"\n    Initializes the EmotionModel.\n    Args:\n        model_name: The name of the model architecture from the timm library.\n        num_classes: The number of output classes (emotions).\n        pretrained: Whether to load ImageNet pretrained weights.\n    \"\"\"\n    super().__init__()\n    # Load the pretrained backbone\n    # in_chans=1 are grayscale but 3 is safer for standard ResNet\n    self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes, in_chans=3)\n</code></pre>"},{"location":"my_api/#group50.data.load_data","title":"group50.data.load_data","text":"<pre><code>load_data(split_dir: Path) -&gt; tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Load images and targets from the specified directory and returns them as tensors.</p> Source code in <code>group50/data.py</code> <pre><code>def load_data(split_dir: Path) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Load images and targets from the specified directory and returns them as tensors.\"\"\"\n    images, targets = [], []\n    # 1 channel like MNIST from the course, fixed size (48x48) like described and [0,1] format.\n    transform = transforms.Compose(\n        [\n            transforms.Resize((48, 48)),\n            transforms.Grayscale(num_output_channels=3),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ]\n    )\n\n    for class_name in classes:\n        class_dir = split_dir / class_name\n        label = classes_to_idx[class_name]\n\n        if not class_dir.exists():\n            raise FileNotFoundError(f\"Missing directory: {class_dir}\")\n\n        for img_path in class_dir.iterdir():\n            if img_path.suffix.lower() in {\".png\", \".jpg\", \".jpeg\"}:\n                with Image.open(img_path) as img:\n                    img = transform(img)\n                images.append(img)\n                targets.append(label)\n\n    if not images:\n        raise RuntimeError(f\"No images found in {split_dir}\")\n\n    images_tensor = torch.stack(images)  # TO DO: create PyTest to see if [N, 3, 48, 48] is satisfied\n    targets_tensor = torch.tensor(targets, dtype=torch.long)\n\n    return images_tensor, targets_tensor\n</code></pre>"},{"location":"my_api/#group50.data.dataset_statistics","title":"group50.data.dataset_statistics","text":"<pre><code>dataset_statistics(datadir: str = 'data') -&gt; None\n</code></pre> Source code in <code>group50/data.py</code> <pre><code>def dataset_statistics(datadir: str = \"data\") -&gt; None:\n    print(\"Running dataset statistics\")\n    print(\"Data directory:\", datadir)\n\n    files = os.listdir(datadir)\n    print(\"Number of files:\", len(files))\n</code></pre>"}]}